# Music Selector

A TensorFlow-based application that determines personal music preferences by classifying audio files into three categories: **Chills**, **Hypes**, and **Trips**. The system uses Convolutional Neural Networks (CNN) to analyze MFCC (Mel-frequency cepstral coefficients) features extracted from audio files.

## ğŸµ Features

- **Audio Classification**: Automatically categorizes music into three distinct mood-based categories
- **Deep Learning**: Uses CNN architecture for robust feature learning
- **Easy to Use**: Simple API for preprocessing, training, and prediction
- **Visualization**: Built-in performance plotting and data visualization
- **Flexible**: Supports custom datasets and model parameters

## ğŸ“ Project Structure

```
Music_Selector/
â”œâ”€â”€ Music_Selector.ipynb          # Main Jupyter notebook with all functions
â”œâ”€â”€ music_selector.py             # Python module with organized functions
â”œâ”€â”€ API_DOCUMENTATION.md          # Comprehensive API documentation
â”œâ”€â”€ QUICK_START.md               # Quick start guide
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # This file
â””â”€â”€ .gitignore                   # Git ignore file
```

## ğŸš€ Quick Start

### Installation

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd Music_Selector
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Prepare your audio data** (see [Quick Start Guide](QUICK_START.md) for details)

4. **Run the application**:
   ```python
   import music_selector as ms
   model, history, test_acc = ms.complete_workflow()
   ```

## ğŸ“š Documentation

- **[Quick Start Guide](QUICK_START.md)** - Get up and running in 10 minutes
- **[API Documentation](API_DOCUMENTATION.md)** - Comprehensive function reference
- **[Python Module](music_selector.py)** - Organized, reusable code with docstrings

## ğŸ¯ Music Categories

The system classifies music into three categories:

| Category | Label | Description |
|----------|-------|-------------|
| **Chills** | 0 | Relaxing, ambient, and calming music |
| **Hypes** | 1 | Energetic, upbeat, and exciting music |
| **Trips** | 2 | Psychedelic, experimental, and mind-bending music |

## ğŸ”§ How It Works

1. **Audio Processing**: Loads WAV files and segments them into 20-second chunks
2. **Feature Extraction**: Computes MFCC features using librosa
3. **Model Training**: Trains a CNN on the extracted features
4. **Classification**: Predicts music category for new audio files

### Model Architecture

```
Input: (862, 20, 1) MFCC features
â”œâ”€â”€ Conv2D(32, 3x3) + ReLU
â”œâ”€â”€ MaxPooling2D(3x3, stride=2) + BatchNormalization
â”œâ”€â”€ Conv2D(32, 3x3) + ReLU
â”œâ”€â”€ MaxPooling2D(3x3, stride=2) + BatchNormalization
â”œâ”€â”€ Conv2D(32, 2x2) + ReLU
â”œâ”€â”€ MaxPooling2D(3x3, stride=2) + BatchNormalization + Dropout(0.3)
â”œâ”€â”€ Flatten()
â”œâ”€â”€ Dense(64) + ReLU
â””â”€â”€ Dense(10) + Softmax
```

## ğŸ“Š Performance

Typical performance metrics:
- **Training Accuracy**: ~95-100%
- **Validation Accuracy**: ~60-70%
- **Test Accuracy**: ~60-70%

*Note: Performance may vary based on data quality and quantity*

## ğŸ› ï¸ Usage Examples

### Basic Usage

```python
import music_selector as ms

# Run complete workflow
model, history, test_acc = ms.complete_workflow()
```

### Custom Training

```python
import music_selector as ms

# Preprocess data
ms.preprocess_data('Training')
ms.preprocess_data('Test')

# Load and prepare data
train_x, train_y = ms.load_data('Training')
test_x, test_y = ms.load_data('Test')
Xtrain, Xval, Xtest, ytrain, yval, ytest = ms.prepare_datasets(train_x, train_y, 0.2)

# Train with custom parameters
model, history = ms.train_model(
    Xtrain, ytrain, Xval, yval,
    epochs=100,
    batch_size=32,
    learning_rate=0.0001
)

# Evaluate
test_acc, sample_acc = ms.evaluate_model(model, Xtest, ytest)
```

### Individual Predictions

```python
# Make prediction on specific sample
correct = ms.make_prediction(model, Xtest, ytest, 0)
```

## ğŸ“‹ Requirements

### Python Dependencies

- **TensorFlow** >= 2.0.0
- **librosa** >= 0.8.0
- **numpy** >= 1.19.0
- **scikit-learn** >= 0.24.0
- **matplotlib** >= 3.3.0

### Audio Data Requirements

- **Format**: WAV files
- **Naming**: `{type}_{number}.wav` (e.g., `chill_1.wav`, `hype_2.wav`)
- **Duration**: Variable length (segmented into 20-second chunks)
- **Quality**: High-quality audio recommended

## ğŸ—‚ï¸ Data Structure

```
Music_Selector/
â”œâ”€â”€ Training/
â”‚   â”œâ”€â”€ Chills/
â”‚   â”‚   â”œâ”€â”€ chill_1.wav
â”‚   â”‚   â”œâ”€â”€ chill_2.wav
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Hypes/
â”‚   â”‚   â”œâ”€â”€ hype_1.wav
â”‚   â”‚   â”œâ”€â”€ hype_2.wav
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ Trips/
â”‚       â”œâ”€â”€ trip_1.wav
â”‚       â”œâ”€â”€ trip_2.wav
â”‚       â””â”€â”€ ...
â””â”€â”€ Test/
    â”œâ”€â”€ Chills/
    â”œâ”€â”€ Hypes/
    â””â”€â”€ Trips/
```

## ğŸ” Troubleshooting

### Common Issues

1. **Import errors**: Install dependencies with `pip install -r requirements.txt`
2. **File not found**: Check directory structure and file naming
3. **Memory errors**: Reduce batch size or audio segment length
4. **Poor performance**: Verify audio quality and labeling

For detailed troubleshooting, see the [Quick Start Guide](QUICK_START.md).

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is open source. Please refer to the original repository for licensing information.

## ğŸ™ Acknowledgments

- **librosa**: Audio processing library
- **TensorFlow**: Deep learning framework
- **scikit-learn**: Machine learning utilities

## ğŸ“ Support

For questions and support:
- Check the [API Documentation](API_DOCUMENTATION.md)
- Review the [Quick Start Guide](QUICK_START.md)
- Examine the [Python module](music_selector.py) for detailed function documentation

---

**Happy Music Classification! ğŸµğŸ¶**
